{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95aff841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): | DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "- DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "\\ DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /pytorch/osx-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!conda install --prefix {sys.prefix} -y -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9210437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/samheckle/anaconda3/lib/python3.11/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f69933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/samheckle/anaconda3/lib/python3.11/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f860619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e134dfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "print(pipeline('sentiment-analysis')('we love you'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fc2c8",
   "metadata": {},
   "source": [
    "you can use a different model that isn't gpt2! i'm just partial to it because it is incorrect sometimes and is more poetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7851374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f363a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be052e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Two roads diverged in a yellow wood, and only a single car was found dead on the roadway (at least a dozen cars on a white Ford F150 on Sunday night) following a collision south of Los Angeles International Airport. A man in a'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Two roads diverged in a yellow wood, and')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75ee66",
   "metadata": {},
   "source": [
    "how we can index into the returned list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac23681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Two roads diverged in a yellow wood, and that is, it has to come with two different parts. And the road should be different from a road where the people don't want to go. And we don't want that person going out on\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Two roads diverged in a yellow wood, and')[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0d089ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my review of the barbie movie:\\nReeves said:\\nThe movie was very clear that the bar is more than a restaurant like this. As such, the drinks were all from the local food chain. They were from the very food'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('my review of the barbie movie:\\n')[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ffdd450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my review of the barbie movie:\n",
      "\n",
      "\"If the guys were serious about opening it to the crowd and saying 'I went with it, we'll have to start singing and performing.' They never got to do anything and never let anybody ever\n"
     ]
    }
   ],
   "source": [
    "print(generator('my review of the barbie movie:\\n')[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f58ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood, and the yellow-roofed car sped toward the intersection, and was still going on.\\n\\n\\n\\n\\n\"The car is a small, gray Volvo, and it is not completely new,\" the van driver explained.\\nThe red Hyundai-SV-6 parked on a street side of the main street. It started running along the front end of town, but the van driver eventually came to the back of the car.\\n\"The car is still going on,\" the van driver said, \"I tried to contact the police, but my phone never came back and I tried to contact the police. When I got there, they said they were going to arrest me. They said I would take the car and give it to police.\"\\nThe van driver said the red Hyundai-SV-6 went into a back parking lot and began speeding.\\n\"The police say it was a white Volvo while their van was parked at the front of city gate, so they came out and chased the car until they got back in front of the road,\" the driver said.\\nIt is unclear how long the van driver ran into the car until it ended up facing the police.\\nThe'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Two roads diverged in a yellow wood, and', max_length=250)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189d3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, and the yellow-roofed car sped toward the intersection, and was still going on.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"The car is a small, gray Volvo, and it is not completely new,\" the van driver explained.\n",
      "The red Hyundai-SV-6 parked on a street side of the main street. It started running along the front end of town, but the van driver eventually came to the back of the car.\n",
      "\"The car is still going on,\" the van driver said, \"I tried to contact the police, but my phone never came back and I tried to contact the police. When I got there, they said they were going to arrest me. They said I would take the car and give it to police.\"\n",
      "The van driver said the red Hyundai-SV-6 went into a back parking lot and began speeding.\n",
      "\"The police say it was a white Volvo while their van was parked at the front of city gate, so they came out and chased the car until they got back in front of the road,\" the driver said.\n",
      "It is unclear how long the van driver ran into the car until it ended up facing the police.\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "print('Two roads diverged in a yellow wood, and the yellow-roofed car sped toward the intersection, and was still going on.\\n\\n\\n\\n\\n\"The car is a small, gray Volvo, and it is not completely new,\" the van driver explained.\\nThe red Hyundai-SV-6 parked on a street side of the main street. It started running along the front end of town, but the van driver eventually came to the back of the car.\\n\"The car is still going on,\" the van driver said, \"I tried to contact the police, but my phone never came back and I tried to contact the police. When I got there, they said they were going to arrest me. They said I would take the car and give it to police.\"\\nThe van driver said the red Hyundai-SV-6 went into a back parking lot and began speeding.\\n\"The police say it was a white Volvo while their van was parked at the front of city gate, so they came out and chased the car until they got back in front of the road,\" the driver said.\\nIt is unclear how long the van driver ran into the car until it ended up facing the police.\\nThe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2555ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood, and the two cars were stopped by police.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Two roads diverged in a yellow wood, and', temperature=0.1, max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ecd89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood, and the road was blocked by a fence.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Two roads diverged in a yellow wood, and', top_k=1, max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6600dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"It was a dark and stormy time. That is how I described it—my dad and I were in a taxi, in a limousine, on the pavement screaming, 'I'm taking something away!' I told Dad she was afraid that\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('It was a dark and stormy', bad_words_ids=tokenizer(['night', 'day']).input_ids)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d86908b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/samheckle/anaconda3/lib/python3.11/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555f74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not necessary if you -want- to use an entire book\n",
    "with open(\"twilight_new.txt\", \"w\") as fh:\n",
    "    fh.write(open(\"twilight.txt\").read()[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d51bfc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f1ffe4f29946ec89a6d89e63e52931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3cc98ec7c848b3a330d7bc025dc779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27158f2fea1d41c6ac708ede187df40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = datasets.load_dataset('text', data_files='twilight_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1306a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da96d81ae10943d49903a81ee18cb274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenized_training_data = training_data.map(lambda x: tokenizer(x['text']), remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5314a2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39651eff39e64ecb869dc29e99c6c6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/436 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "block_size = 64\n",
    "# magic from https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "lm_training_data = tokenized_training_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "618dbe13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/samheckle/anaconda3/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: filelock in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2023.3.0)\n",
      "Requirement already satisfied: requests in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/samheckle/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d49a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8060e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                 train_dataset=lm_training_data['train'],\n",
    "                 args=TrainingArguments(\n",
    "                     output_dir='distilgpt2-twilight',\n",
    "                     num_train_epochs=1,\n",
    "                     do_train=True,\n",
    "                     do_eval=False\n",
    "                 ),\n",
    "                 tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75d1d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6d28b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "twilight_tokenizer = AutoTokenizer.from_pretrained('distilgpt2-twilight')\n",
    "twilight_model = AutoModelForCausalLM.from_pretrained('distilgpt2-twilight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "107be71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twilight_generator = pipeline('text-generation', model=twilight_model, tokenizer=twilight_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32fa2a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I stared without breathing 〜〜〜〜 “〜〜“──〜〜〜〜〜〜〜。 After a few breaths and a few more breathing, my head went'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twilight_generator('I stared without breathing ')[0]['generated_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
